#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§ª TEST MODE ML COMPLET AVEC TENSORFLOW - SKILLSYNC
"""

import requests
import json
import time
import sys
from datetime import datetime

def print_header(title):
    print("\n" + "="*70)
    print(f"ğŸ§ª {title}")
    print("="*70)

def test_server_connection():
    """Test de connexion au serveur"""
    print("\nğŸŒ Test connexion serveur...")
    try:
        response = requests.get("http://localhost:8000/", timeout=10)
        if response.status_code == 200:
            print("âœ… Serveur backend actif")
            return True
        else:
            print(f"âŒ Serveur erreur HTTP: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ Serveur inaccessible - dÃ©marrer avec: python main_simple_for_frontend.py")
        return False
    except Exception as e:
        print(f"âŒ Erreur connexion serveur: {e}")
        return False

def test_ml_status_detailed():
    """Test dÃ©taillÃ© du statut ML"""
    print("\nğŸ§  Test statut ML dÃ©taillÃ©...")
    try:
        response = requests.get("http://localhost:8000/api/v1/ml/status", timeout=15)
        if response.status_code == 200:
            data = response.json()
            print("âœ… Endpoint ML status actif")
            
            # Affichage dÃ©taillÃ© du statut
            print(f"\nğŸ“Š STATUT ML COMPLET:")
            print(f"   ğŸ¤– ML ActivÃ©: {data.get('ml_enabled', 'N/A')}")
            print(f"   ğŸ”§ Type ML: {data.get('ml_mode_type', 'N/A')}")
            print(f"   âš™ï¸ Moteur: {data.get('engine_type', 'N/A')}")
            print(f"   ğŸ“ Version: {data.get('version', 'N/A')}")
            
            # CapacitÃ©s ML
            capabilities = data.get('capabilities', {})
            print(f"\nğŸ¯ CAPACITÃ‰S ML:")
            for cap, enabled in capabilities.items():
                status = "âœ…" if enabled else "âŒ"
                print(f"   {status} {cap}")
            
            # ModÃ¨les chargÃ©s
            models = data.get('models_loaded', {})
            print(f"\nğŸ§  MODÃˆLES CHARGÃ‰S:")
            for model, loaded in models.items():
                status = "âœ…" if loaded else "âŒ"
                print(f"   {status} {model}")
            
            # Performance
            performance = data.get('performance', {})
            print(f"\nâš¡ PERFORMANCE:")
            print(f"   ğŸƒ Mode: {performance.get('mode', 'N/A')}")
            print(f"   ğŸš€ Vitesse: {performance.get('speed', 'N/A')}")
            print(f"   ğŸ¯ PrÃ©cision: {performance.get('accuracy', 'N/A')}")
            
            # VÃ©rifier si TensorFlow est actif
            tensorflow_active = (
                data.get('ml_mode_type') == 'full' and
                data.get('capabilities', {}).get('tensorflow_models', False)
            )
            
            if tensorflow_active:
                print("\nğŸ‰ TENSORFLOW DÃ‰TECTÃ‰ ET ACTIF!")
                return True
            else:
                print("\nâš ï¸ TensorFlow non dÃ©tectÃ© - vÃ©rifier l'installation")
                return False
                
        else:
            print(f"âŒ ML Status erreur HTTP: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Test ML status Ã©chouÃ©: {e}")
        return False

def test_tensorflow_recommendations():
    """Test spÃ©cifique des recommandations TensorFlow"""
    print("\nğŸ§  Test recommandations TensorFlow...")
    
    # Profil de test complexe pour TensorFlow
    test_profile = {
        "current_role": "DÃ©veloppeur Full-Stack Senior",
        "target_role": "Architecte Solutions IA",
        "skills": ["Python", "JavaScript", "TensorFlow", "Kubernetes", "AWS", "React"],
        "experience_years": 5,
        "industry": "FinTech"
    }
    
    try:
        print(f"   ğŸ‘¤ Profil test: {test_profile['current_role']} -> {test_profile['target_role']}")
        print(f"   ğŸ› ï¸ CompÃ©tences: {', '.join(test_profile['skills'])}")
        
        response = requests.post(
            "http://localhost:8000/api/v1/recommendations",
            json=test_profile,
            timeout=45  # Timeout gÃ©nÃ©reux pour TensorFlow
        )
        
        if response.status_code == 200:
            data = response.json()
            print("âœ… Recommandations TensorFlow gÃ©nÃ©rÃ©es")
            
            # Analyser la qualitÃ© des recommandations
            engine_info = data.get('engine_info', {})
            print(f"\nğŸ”§ MOTEUR UTILISÃ‰:")
            print(f"   ğŸ¤– Type: {engine_info.get('engine_type', 'N/A')}")
            print(f"   ğŸ“ Version: {engine_info.get('version', 'N/A')}")
            print(f"   ğŸ§  ML ActivÃ©: {engine_info.get('ml_mode_enabled', 'N/A')}")
            print(f"   ğŸ”§ Type ML: {engine_info.get('ml_mode_type', 'N/A')}")
            
            # Analyser les recommandations
            recommendations = data.get('recommendations', {})
            total_recommendations = 0
            valid_scores = 0
            valid_titles = 0
            
            for category, items in recommendations.items():
                if isinstance(items, list):
                    total_recommendations += len(items)
                    for item in items:
                        if item.get('priority_score', 0) > 0:
                            valid_scores += 1
                        if item.get('title') and item['title'] != 'N/A':
                            valid_titles += 1
            
            print(f"\nğŸ“Š QUALITÃ‰ RECOMMANDATIONS:")
            print(f"   ğŸ“‹ Total: {total_recommendations}")
            print(f"   ğŸ¯ Scores valides: {valid_scores}/{total_recommendations}")
            print(f"   ğŸ“ Titres valides: {valid_titles}/{total_recommendations}")
            
            # Afficher quelques exemples
            immediate_actions = recommendations.get('IMMEDIATE_ACTIONS', [])
            if immediate_actions:
                print(f"\nğŸ¯ EXEMPLES D'ACTIONS IMMÃ‰DIATES:")
                for i, action in enumerate(immediate_actions[:3], 1):
                    title = action.get('title', 'N/A')
                    score = action.get('priority_score', 0)
                    description = action.get('description', 'N/A')[:80] + '...'
                    print(f"   {i}. {title} (Score: {score}%)")
                    print(f"      {description}")
            
            # DÃ©terminer le succÃ¨s
            quality_threshold = 0.8  # 80% de qualitÃ© minimum
            if (valid_scores >= total_recommendations * quality_threshold and 
                valid_titles >= total_recommendations * quality_threshold):
                print("\nğŸŒŸ QUALITÃ‰ EXCELLENTE - TensorFlow fonctionne parfaitement!")
                return True
            else:
                print("\nâš ï¸ QualitÃ© modÃ©rÃ©e - TensorFlow partiellement fonctionnel")
                return False
                
        else:
            print(f"âŒ Recommandations erreur HTTP: {response.status_code}")
            if response.text:
                print(f"   ğŸ“„ RÃ©ponse: {response.text[:200]}...")
            return False
            
    except requests.exceptions.Timeout:
        print("â° Timeout lors des recommandations TensorFlow")
        print("   ğŸ’¡ Ceci peut indiquer que TensorFlow charge ses modÃ¨les")
        return False
    except Exception as e:
        print(f"âŒ Test recommandations TensorFlow Ã©chouÃ©: {e}")
        return False

def test_tensorflow_models_locally():
    """Test local des modÃ¨les TensorFlow"""
    print("\nğŸ”¬ Test local des modÃ¨les TensorFlow...")
    
    try:
        # Test d'import TensorFlow
        import tensorflow as tf
        print(f"   âœ… TensorFlow {tf.__version__} importÃ©")
        
        # Test de crÃ©ation de modÃ¨le
        print("   ğŸ—ï¸ CrÃ©ation modÃ¨le neural scorer...")
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(128, activation='relu', input_shape=(384,)),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        print("   âœ… ModÃ¨le TensorFlow crÃ©Ã©")
        
        # Test de prÃ©diction
        import numpy as np
        test_input = np.random.random((1, 384))
        prediction = model.predict(test_input, verbose=0)
        score = prediction[0][0]
        print(f"   âœ… PrÃ©diction test: {score:.4f}")
        
        # Test des autres composants
        try:
            from transformers import AutoTokenizer, AutoModel
            print("   âœ… Transformers disponible")
        except ImportError:
            print("   âš ï¸ Transformers manquant")
        
        try:
            from sentence_transformers import SentenceTransformer
            print("   âœ… Sentence-Transformers disponible")
        except ImportError:
            print("   âš ï¸ Sentence-Transformers manquant")
        
        print("\nğŸ‰ TENSORFLOW ENTIÃˆREMENT FONCTIONNEL!")
        return True
        
    except ImportError as e:
        print(f"   âŒ Import TensorFlow Ã©chouÃ©: {e}")
        return False
    except Exception as e:
        print(f"   âŒ Test TensorFlow local Ã©chouÃ©: {e}")
        return False

def run_complete_tensorflow_test():
    """Test complet du mode ML avec TensorFlow"""
    print_header("TEST COMPLET MODE ML TENSORFLOW - SKILLSYNC")
    print(f"ğŸ•’ DÃ©marrÃ© Ã : {datetime.now().strftime('%H:%M:%S')}")
    
    results = {
        "server_connection": False,
        "ml_status": False,
        "tensorflow_local": False,
        "tensorflow_recommendations": False
    }
    
    # Tests sÃ©quentiels
    print("\nğŸš€ DÃ‰MARRAGE DES TESTS TENSORFLOW...")
    
    # 1. Test connexion serveur
    results["server_connection"] = test_server_connection()
    
    # 2. Test local TensorFlow
    results["tensorflow_local"] = test_tensorflow_models_locally()
    
    if results["server_connection"]:
        # 3. Test ML status
        results["ml_status"] = test_ml_status_detailed()
        
        # 4. Test recommandations TensorFlow
        results["tensorflow_recommendations"] = test_tensorflow_recommendations()
    
    # Analyse des rÃ©sultats
    print_header("RÃ‰SULTATS FINAUX TENSORFLOW")
    total_tests = len(results)
    passed_tests = sum(results.values())
    success_rate = (passed_tests / total_tests) * 100
    
    print(f"ğŸ“Š Tests rÃ©ussis: {passed_tests}/{total_tests}")
    print(f"ğŸ“ˆ Taux de succÃ¨s: {success_rate:.1f}%")
    
    print("\nğŸ“‹ DÃ‰TAIL DES RÃ‰SULTATS:")
    for test, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        test_name = test.replace('_', ' ').title()
        print(f"   {test_name}: {status}")
    
    # Conclusion
    if passed_tests == total_tests:
        print("\nğŸ‰ TENSORFLOW MODE ML 100% FONCTIONNEL!")
        print("ğŸš€ Votre systÃ¨me SkillSync utilise maintenant l'IA avancÃ©e")
        print("ğŸ’¡ Les recommandations sont gÃ©nÃ©rÃ©es par des rÃ©seaux de neurones TensorFlow")
    elif passed_tests >= 3:
        print("\nâœ… TENSORFLOW MAJORITAIREMENT FONCTIONNEL")
        print("âš™ï¸ Quelques ajustements mineurs possibles")
    elif results["tensorflow_local"]:
        print("\nâš ï¸ TENSORFLOW INSTALLÃ‰ MAIS PROBLÃˆMES DE CONFIGURATION")
        print("ğŸ”§ VÃ©rifier la configuration du serveur backend")
    else:
        print("\nâŒ TENSORFLOW NON FONCTIONNEL")
        print("ğŸ’Š Solutions:")
        print("   1. Relancer: python install_tensorflow_full.py")
        print("   2. Installation manuelle: pip install tensorflow")
        print("   3. VÃ©rifier les logs d'erreur ci-dessus")
    
    print(f"\nğŸ•’ TerminÃ© Ã : {datetime.now().strftime('%H:%M:%S')}")
    return passed_tests == total_tests

if __name__ == "__main__":
    try:
        success = run_complete_tensorflow_test()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâŒ Tests interrompus par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Erreur inattendue dans les tests: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
