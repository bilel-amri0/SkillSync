import requests
import json
import time

print("="*80)
print("COMPREHENSIVE ML CAREER GUIDANCE TEST")
print("="*80)

# More detailed CV
cv = """
BILEL AMRI
Senior Machine Learning Engineer
Email: bilel.amri@example.com | Phone: +1-555-0123
Location: San Francisco, CA
LinkedIn: linkedin.com/in/bilelamri | GitHub: github.com/bilelamri

PROFESSIONAL SUMMARY
Senior Machine Learning Engineer with 5 years of experience building and deploying 
ML models at scale. Expert in deep learning, NLP, computer vision, and MLOps. 
Strong background in Python, TensorFlow, PyTorch, and cloud infrastructure (AWS/GCP).
Passionate about using AI to solve real-world problems and mentor junior engineers.

WORK EXPERIENCE

Senior ML Engineer | TechCorp AI Division | San Francisco, CA | 2022 - Present
‚Ä¢ Led team of 4 ML engineers building recommendation systems serving 10M+ users
‚Ä¢ Designed and deployed 15+ deep learning models using TensorFlow and PyTorch
‚Ä¢ Implemented MLOps pipeline with Docker, Kubernetes, Jenkins, reducing deployment time by 60%
‚Ä¢ Built real-time data pipelines processing 50TB+ data daily using Apache Spark and Kafka
‚Ä¢ Improved model accuracy by 35% through advanced feature engineering and hyperparameter tuning
‚Ä¢ Collaborated with product, data science, and engineering teams on ML product roadmap
‚Ä¢ Technologies: Python, TensorFlow, PyTorch, Scikit-learn, Docker, Kubernetes, AWS SageMaker

Machine Learning Engineer | DataStart Inc. | San Jose, CA | 2020 - 2022  
‚Ä¢ Developed NLP models for text classification and sentiment analysis with 92% accuracy
‚Ä¢ Built computer vision models for object detection and image segmentation
‚Ä¢ Created data preprocessing pipelines using Pandas, NumPy, and Apache Airflow
‚Ä¢ Deployed models to production using FastAPI, Flask, and AWS Lambda
‚Ä¢ Implemented A/B testing framework to measure model performance in production
‚Ä¢ Technologies: Python, Keras, Scikit-learn, NLTK, OpenCV, FastAPI, PostgreSQL

Software Engineer | WebTech Solutions | Palo Alto, CA | 2018 - 2020
‚Ä¢ Built full-stack web applications using React, Node.js, and MongoDB
‚Ä¢ Developed RESTful APIs serving 1M+ requests per day
‚Ä¢ Implemented CI/CD pipelines with Jenkins and GitHub Actions
‚Ä¢ Managed PostgreSQL and Redis databases for high-traffic applications
‚Ä¢ Technologies: JavaScript, React, Node.js, Express, MongoDB, PostgreSQL, AWS

EDUCATION
Master of Science in Computer Science - Machine Learning
Stanford University | 2017 - 2019 | GPA: 3.9/4.0
Focus: Deep Learning, Natural Language Processing, Computer Vision

Bachelor of Science in Computer Engineering  
UC Berkeley | 2013 - 2017 | GPA: 3.7/4.0

TECHNICAL SKILLS
‚Ä¢ Languages: Python, JavaScript, SQL, Java, C++, R
‚Ä¢ ML/DL Frameworks: TensorFlow, PyTorch, Keras, Scikit-learn, Hugging Face, LangChain
‚Ä¢ Data Science: Pandas, NumPy, Matplotlib, Seaborn, Jupyter, Scipy
‚Ä¢ MLOps: Docker, Kubernetes, Jenkins, MLflow, W&B, Airflow, CI/CD
‚Ä¢ Cloud: AWS (SageMaker, EC2, S3, Lambda), GCP (Vertex AI, BigQuery), Azure
‚Ä¢ Databases: PostgreSQL, MongoDB, Redis, Elasticsearch, Neo4j
‚Ä¢ Big Data: Apache Spark, Kafka, Hadoop, Hive
‚Ä¢ Web: FastAPI, Flask, Django, React, Node.js, GraphQL
‚Ä¢ Tools: Git, Linux, Vim, VS Code, Postman

CERTIFICATIONS
‚Ä¢ AWS Certified Machine Learning - Specialty (2023)
‚Ä¢ TensorFlow Developer Certificate (2022)
‚Ä¢ AWS Certified Solutions Architect - Associate (2021)

PROJECTS
‚Ä¢ AI Resume Analyzer: Built end-to-end ML system analyzing resumes using NLP and providing 
  career guidance. Used BERT for skill extraction, implemented recommendation engine.
  Tech: Python, TensorFlow, FastAPI, React, PostgreSQL, Docker
  
‚Ä¢ Stock Price Predictor: LSTM-based model for time series forecasting of stock prices.
  Achieved 85% directional accuracy. Deployed as web app with real-time predictions.
  Tech: PyTorch, Pandas, Flask, React, AWS

‚Ä¢ Image Recognition API: Production-ready computer vision API for object detection and 
  classification. Serving 100k+ requests daily with 99.9% uptime.
  Tech: PyTorch, FastAPI, Docker, Kubernetes, AWS
"""

print(f"\nüìÑ Testing with comprehensive CV ({len(cv)} characters)")
print("‚è≥ Sending to ML career guidance API...")
print("   (First request may take 20-30s to load ML models)")

try:
    start = time.time()
    response = requests.post(
        'http://localhost:8001/api/v1/career-guidance',
        json={'cv_content': cv},
        timeout=90
    )
    elapsed = time.time() - start
    
    print(f"\n‚úÖ Response received in {elapsed:.2f}s")
    print(f"   HTTP Status: {response.status_code}")
    
    if response.status_code == 200:
        result = response.json()
        
        # Save full result
        with open('comprehensive_ml_result.json', 'w') as f:
            json.dump(result, f, indent=2)
        print("   üíæ Full result saved to: comprehensive_ml_result.json")
        
        # Display results
        print("\n" + "="*80)
        print("üìä ML ANALYSIS RESULTS")
        print("="*80)
        
        # Metadata
        meta = result.get('metadata', {})
        print(f"\nü§ñ ML ENGINE:")
        print(f"   Model: {meta.get('ml_model', 'N/A')}")
        print(f"   Version: {meta.get('engine_version', 'N/A')}")
        print(f"   Processing time: {meta.get('processing_time_seconds', 0):.2f}s")
        print(f"   Skills extracted: {meta.get('cv_skills_count', 0)}")
        
        # Job Recommendations
        jobs = result.get('job_recommendations', [])
        print(f"\nüíº JOB RECOMMENDATIONS: {len(jobs)}")
        if jobs:
            for i, job in enumerate(jobs[:3], 1):
                print(f"\n   {i}. {job['title']}")
                print(f"      ü§ñ ML Similarity: {job['similarity_score']*100:.1f}%")
                print(f"      üéØ ML Confidence: {job['confidence']*100:.1f}%")
                salary = job['predicted_salary']
                print(f"      üí∞ Predicted Salary: ${salary['min']:,} - ${salary['max']:,}")
                print(f"      üìà Growth Potential: {job['growth_potential']}")
                print(f"      ‚úÖ Matching: {len(job['matching_skills'])} skills")
                print(f"      üìö To Learn: {len(job['skill_gaps'])} skills")
                if job['matching_skills']:
                    print(f"      Skills: {', '.join(job['matching_skills'][:5])}")
        else:
            print("   ‚ö†Ô∏è  No jobs found (similarity threshold not met)")
        
        # Certifications  
        certs = result.get('certification_recommendations', [])
        print(f"\nüéì CERTIFICATION RECOMMENDATIONS: {len(certs)}")
        if certs:
            for i, cert in enumerate(certs[:3], 1):
                print(f"\n   {i}. {cert['name']}")
                print(f"      ü§ñ ML Relevance: {cert['relevance_score']*100:.1f}%")
                print(f"      üéØ Skill Alignment: {cert['skill_alignment']*100:.1f}%")
                print(f"      üí∞ Predicted ROI: {cert['predicted_roi']}")
                print(f"      ‚è±Ô∏è  Time: {cert['estimated_time']}")
                print(f"      üìà Career Boost: {cert['career_boost']}")
        
        # Learning Roadmap
        roadmap = result.get('learning_roadmap', {})
        phases = roadmap.get('phases', [])
        print(f"\nüéØ LEARNING ROADMAP: {len(phases)} phases")
        print(f"   üìÖ Total Duration: {roadmap.get('total_duration_weeks')} weeks ({roadmap.get('total_duration_months')} months)")
        print(f"   üéì Predicted Success: {roadmap.get('predicted_success_rate')}")
        print(f"   ‚ú® Personalization: {roadmap.get('personalization_score')}")
        print(f"   üìö Strategy: {roadmap.get('learning_strategy')}")
        
        if phases:
            for i, phase in enumerate(phases, 1):
                print(f"\n   Phase {i}: {phase['phase_name']}")
                print(f"      Duration: {phase['duration_weeks']} weeks")
                print(f"      Success: {phase['success_probability']}")
                print(f"      Skills: {', '.join(phase['skills_to_learn'][:5])}")
        
        # XAI Insights
        xai = result.get('xai_insights', {})
        confidence = xai.get('ml_confidence_scores', {})
        print(f"\nüß† ML CONFIDENCE SCORES:")
        for key, val in confidence.items():
            print(f"   ‚Ä¢ {key}: {val}")
        
        key_insights = xai.get('key_insights', [])
        print(f"\nüí° KEY INSIGHTS:")
        for insight in key_insights[:5]:
            print(f"   ‚Ä¢ {insight}")
        
        # Summary
        print("\n" + "="*80)
        print("‚úÖ ML CAREER GUIDANCE SYSTEM - ALL TESTS PASSED!")
        print("="*80)
        print(f"\nüìä Summary:")
        print(f"   ‚Ä¢ {len(jobs)} job recommendations (ML-matched)")
        print(f"   ‚Ä¢ {len(certs)} certification recommendations (ML-ranked)")
        print(f"   ‚Ä¢ {len(phases)}-phase learning roadmap (ML-optimized)")
        print(f"   ‚Ä¢ Complete XAI explainability")
        print(f"   ‚Ä¢ Processing time: {elapsed:.2f}s")
        
        print(f"\nüìÅ Files created:")
        print(f"   ‚Ä¢ comprehensive_ml_result.json (full ML analysis)")
        
        print(f"\nüìñ Documentation:")
        print(f"   ‚Ä¢ ML_CAREER_SYSTEM_DOCUMENTATION.md")
        print(f"   ‚Ä¢ ML_IMPLEMENTATION_SUMMARY.md")
        
        print("\n" + "="*80 + "\n")
        
    else:
        print(f"\n‚ùå HTTP Error: {response.status_code}")
        print(response.text[:500])
        
except requests.exceptions.Timeout:
    print("\n‚è±Ô∏è  Timeout! Request took >90 seconds")
    print("Note: First ML request may take 20-30s to load models")
except requests.exceptions.ConnectionError:
    print("\n‚ùå Connection Error!")
    print("Make sure backend server is running: cd backend && python start_server.py")
except Exception as e:
    print(f"\n‚ùå Error: {e}")
    import traceback
    traceback.print_exc()
